# Ultralytics 🚀 AGPL-3.0 License - https://ultralytics.com/license

# YOLO12 object detection model with P3/8 - P5/32 outputs
# Model docs: https://docs.ultralytics.com/models/yolo12
# Task docs: https://docs.ultralytics.com/tasks/detect

# Parameters
nc: 80 # number of classes
scales: # model compound scaling constants, i.e. 'model=yolo12n.yaml' will call yolo12.yaml with scale 'n'
  # [depth, width, max_channels]
  n: [0.50, 0.25, 1024] # summary: 272 layers, 2,602,288 parameters, 2,602,272 gradients, 6.7 GFLOPs
  s: [0.50, 0.50, 1024] # summary: 272 layers, 9,284,096 parameters, 9,284,080 gradients, 21.7 GFLOPs
  m: [0.50, 1.00, 512] # summary: 292 layers, 20,199,168 parameters, 20,199,152 gradients, 68.1 GFLOPs
  l: [1.00, 1.00, 512] # summary: 488 layers, 26,450,784 parameters, 26,450,768 gradients, 89.7 GFLOPs
  x: [1.00, 1.50, 512] # summary: 488 layers, 59,210,784 parameters, 59,210,768 gradients, 200.3 GFLOPs

ch: 6

# YOLO12n backbone
backbone:
  # [from, repeats, module, args]
  - [-1, 1, Silence, []]  # 0-P1/2
    # infrared
  - [0, 1, SilenceChannel, [3,6]]  # 1-P1/2   infrared 主分支  把输入和可见光分支交换即可切换主分支，其余不用动  Main branch: To switch to the main branch, simply swap the input and the visible light branch. The rest does not need to be changed.
  - [-1, 1, Conv, [64, 3, 2]] # 2-P1/2
  - [-1, 1, Conv, [128, 3, 2]] # 3-P2/4
  - [-1, 2, C3k2, [256, False, 0.25]]
  - [-1, 1, Conv, [256, 3, 2]] # 5-P3/8
  - [-1, 2, C3k2, [512, False, 0.25]]


  # visible
  - [ 0, 1, SilenceChannel, [ 0,3 ] ]  # 7-P1/2  visible

  - [-1, 1, ZeroConv2d, [ 3,3, 1, 1]] # 8 (P5/32-large)
  - [[1, -1], 1, ADD, []]  # ADD backbone P3   9

  - [ -1, 1, Conv, [ 64, 3, 2 ] ] # 10-P1/2
  - [ -1, 1, Conv, [ 128, 3, 2 ] ] # 11-P2/4
  - [ -1, 2, C3k2, [ 256, False, 0.25 ] ]
  - [ -1, 1, Conv, [ 256, 3, 2 ] ] # 13-P3/8
  - [ -1, 2, C3k2, [ 512, False, 0.25 ] ] # 14

  - [-1, 1, ZeroConv2d, [ 512,3, 1, 1]] # 15 (P3/32-)
  - [[6, -1], 1, ADD, []]  # ADD backbone P3   16


  - [ 16, 1, Conv, [ 512, 3, 2 ] ] # 17-P4/16  infrared
  - [ -1, 4, A2C2f, [512, True, 4] ]

  - [ 14, 1, Conv, [ 512, 3, 2 ] ] # 19-P4/16   visible
  - [ -1, 4, A2C2f, [512, True, 4]]  #20

  - [-1, 1, ZeroConv2d, [ 512, 3, 1, 1]] # 21 (P4/16-)
  - [[18, -1], 1, ADD, []]  # ADD backbone P3   22


  - [ 22, 1, Conv, [ 1024, 3, 2 ] ] # 23-P5/32  infrared
  - [ -1,  4, A2C2f, [1024, True, 1] ]

  - [ 20, 1, Conv, [ 1024, 3, 2 ] ] # 25-P5/32  visible
  - [ -1, 4, A2C2f, [1024, True, 1] ]  #26


  - [ -1, 1, ZeroConv2d, [ 1024,3, 1,1 ] ] # 27 (P5/32-large)
  - [ [ 24, -1 ], 1, ADD, [ ] ]  # ADD backbone P3   28


# YOLO12n head
head:
  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 22], 1, Concat, [1]] # cat backbone P4
  - [-1, 2, A2C2f, [512, False, -1]] # 31

  - [-1, 1, nn.Upsample, [None, 2, "nearest"]]
  - [[-1, 16], 1, Concat, [1]] # cat backbone P3
  - [-1, 2, A2C2f, [256, False, -1]] # 34

  - [-1, 1, Conv, [256, 3, 2]]
  - [[-1, 31], 1, Concat, [1]] # cat head P4
  - [-1, 2, A2C2f, [512, False, -1]] # 37

  - [-1, 1, Conv, [512, 3, 2]]
  - [[-1, 28], 1, Concat, [1]] # cat head P5
  - [-1, 2, C3k2, [1024, True]] # 40 (P5/32-large)

  - [[34, 37, 40], 1, Detect, [nc]] # Detect(P3, P4, P5)
